{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83ca2b02-db47-4ccd-b13a-e2d546bc7ddd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Morphometrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58f70816-2395-4516-b6c9-60345f7cfca3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e04804-85e1-4647-86de-28f9976fa824",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1cc15a3-1c0f-45a4-8fbc-350e8f9fe4b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reverse_bearing(x):\n",
    "    return x + 180 if x < 180 else x - 180\n",
    "\n",
    "def get_bearings(G, ID):\n",
    "    # calculate the edge bearings\n",
    "    Gu = ox.add_edge_bearings(ox.get_undirected(G))\n",
    "    \n",
    "    weight_by_length = False\n",
    "\n",
    "    bearings = {}\n",
    "    if weight_by_length:\n",
    "        # weight bearings by length (meters)\n",
    "        city_bearings = []\n",
    "        for u, v, k, d in Gu.edges(keys=True, data=True):\n",
    "            city_bearings.extend([d['bearing']] * int(d['length']))\n",
    "        b = pd.Series(city_bearings)\n",
    "        bearings[ID] = pd.concat([b, b.map(reverse_bearing)]).reset_index(drop='True')\n",
    "    else:\n",
    "        # don't weight bearings, just take one value per street segment\n",
    "        b = pd.Series([d['bearing'] for u, v, k, d in Gu.edges(keys=True, data=True)])\n",
    "        bearings[ID] = pd.concat([b, b.map(reverse_bearing)]).reset_index(drop='True')\n",
    "    return bearings[ID]\n",
    "\n",
    "def count_and_merge(n, bearings):\n",
    "    # make twice as many bins as desired, then merge them in pairs\n",
    "    # prevents bin-edge effects around common values like 0째 and 90째\n",
    "    n = n * 2\n",
    "    bins = np.arange(n + 1) * 360 / n\n",
    "    count, _ = np.histogram(bearings, bins=bins)\n",
    "    \n",
    "    # move the last bin to the front, so eg 0.01째 and 359.99째 will be binned together\n",
    "    count = np.roll(count, 1)\n",
    "    return count[::2] + count[1::2]\n",
    "\n",
    "def get_orientation_order(count):  \n",
    "    try:\n",
    "        H0 = 0\n",
    "        for i in range(len(count)):\n",
    "            Pi = (count[i]/sum(count))\n",
    "            if Pi != 0:\n",
    "                H0 += Pi*np.log(Pi)\n",
    "\n",
    "        H0 = -1*H0\n",
    "        Hmax = np.log(len(count))\n",
    "        Hg = np.log(2)\n",
    "\n",
    "        orientation_order = (1 - (((H0-Hg)/(Hmax-Hg))**2))\n",
    "   \n",
    "    except Exception as e:\n",
    "        print(f'Error in orientation order {e}')\n",
    "\n",
    "    return orientation_order\n",
    "\n",
    "##### Functions to calculate compactness\n",
    "\n",
    "\n",
    "def pp_compactness(geom): # Polsby-Popper\n",
    "    p = geom.length\n",
    "    a = geom.area    \n",
    "    return (4*pi*a)/(p*p)\n",
    "\n",
    "##### Functions to calculate fractal dimension\n",
    "\n",
    "def fractal_dimension(Z, threshold=0.8):\n",
    "    \"\"\"Returns box-counting dimension of a 2D array.\n",
    "    Args:\n",
    "        Z: 2D array to be analysed.\n",
    "        threshold: Cutoff for converting values in Z to 1 and 0.\n",
    "    Returns:\n",
    "        The estimated box counting dimension.\n",
    "    \"\"\"\n",
    "    # Only for 2d image\n",
    "    assert(len(Z.shape) == 2)\n",
    "    def boxcount(Z, k):\n",
    "        S = np.add.reduceat(np.add.reduceat(Z, np.arange(0, Z.shape[0], k), axis=0), np.arange(0, Z.shape[1], k), axis=1)\n",
    "        # We count non-empty (0) and non-full boxes (k*k)\n",
    "        return len(np.where((S > 0) & (S < k*k))[0])\n",
    "    # Transform Z into a binary array\n",
    "    Z = (Z < threshold)\n",
    "    # Minimal dimension of image\n",
    "    p = min(Z.shape)\n",
    "    # Greatest power of 2 less than or equal to p\n",
    "    n = 2**np.floor(np.log(p)/np.log(2))\n",
    "    # Extract the exponent\n",
    "    n = int(np.log(n)/np.log(2))\n",
    "    # Build successive box sizes (from 2**n down to 2**1)\n",
    "    sizes = 2**np.arange(n, 1, -1)\n",
    "    # Actual box counting with decreasing size\n",
    "    counts = []\n",
    "    for size in sizes:\n",
    "        counts.append(boxcount(Z, size))\n",
    "    # Fit the successive log(sizes) with log (counts)\n",
    "    coeffs = np.polyfit(np.log(sizes), np.log(counts), 1)\n",
    "    return -coeffs[0]\n",
    "\n",
    "##### Function to clean building heights\n",
    "\n",
    "def clean_heights(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e235e16-fcfb-4f9a-9fdd-f23d5b9454f1",
   "metadata": {},
   "source": [
    "# Choose city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61c9263a-4515-465f-a2ad-a0d2d71bffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: Los Angeles\n",
      "Reading: ../data/admin-levels/Los Angeles.gpkg\n"
     ]
    }
   ],
   "source": [
    "city_list = [\n",
    "    'Melbourne',\n",
    "    'Jerusalem',\n",
    "    'Buenos Aires',\n",
    "    'Paris',\n",
    "    'Rotterdam',\n",
    "    'Nashville',\n",
    "    'Singapore',\n",
    "    'Cape Town',\n",
    "    'New York',\n",
    "    'Los Angeles',\n",
    "    'Chicago',\n",
    "    'Boston',\n",
    "    'Austin',\n",
    "    'Seattle',\n",
    "    'Philadelphia',\n",
    "    'Pittsburgh',\n",
    "    'Washington DC',\n",
    "    'San Francisco',\n",
    "    'SF Bay Area ',\n",
    "    'Raleigh',\n",
    "    'Milwaukee',\n",
    "    'Portland',\n",
    "    'San Diego',\n",
    "    'Denver',\n",
    "    'Miami',\n",
    "    'Saint Louis',\n",
    "    'Houston',\n",
    "    'Atlanta',\n",
    "    'Phoenix',\n",
    "    'Detroit',\n",
    "    'Minneapolis',\n",
    "    'Savannah',\n",
    "    'Charlotte',\n",
    "    'Las Vegas',\n",
    "    'Cincinnati',\n",
    "    'Kansas City',\n",
    "    'Nashville']\n",
    "\n",
    "\n",
    "city = city_list[9]\n",
    "print(\"City:\", city)\n",
    "\n",
    "data_folder = Path(\"../data\")\n",
    "input_file = data_folder / \"0_boundaries\" / (city + \".gpkg\")\n",
    "print(\"Reading:\", input_file)\n",
    "gdf = gpd.read_file(input_file, driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43751fdd-2dc8-4881-af02-0395bb596f8b",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6504b97-9afa-4449-aa5d-0e0733023140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf['Center_point'] = gdf['geometry'].centroid\n",
    "#Extract lat and lon from the centerpoint\n",
    "\n",
    "gdf['lon'] = gdf.Center_point.map(lambda p: p.x)\n",
    "gdf['lat'] = gdf.Center_point.map(lambda p: p.y)\n",
    "\n",
    "gdf = gdf.drop(['Center_point'], axis = 1)\n",
    "\n",
    "# Ensure crs is correct\n",
    "\n",
    "gdf = ox.project_gdf(gdf,to_crs='epsg:4326',to_latlong=False) \n",
    "\n",
    "# Calculate area of every shape\n",
    "\n",
    "temp = gdf.copy()\n",
    "temp = temp.to_crs({'init': 'epsg:32630'})\n",
    "temp[\"area_m^2\"] = temp['geometry'].area\n",
    "gdf[\"area_m^2\"] = temp[\"area_m^2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cc6016-d031-4fd8-9d53-f8b5c68ad579",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a38a2137-5ce5-41c6-be93-f9ebe420d280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale Complexity\n",
    "gdf['fractal-dimension'] = np.nan\n",
    "gdf['compactness-area'] = np.nan\n",
    "gdf['diameter-periphery'] = np.nan\n",
    "\n",
    "# Spatial Complexity and Connectivity\n",
    "gdf['shannon_entropy-street_orientation_order'] = np.nan\n",
    "gdf['avg_streets_per_node'] = np.nan\n",
    "gdf['avg_proportion_streets_per_node'] = np.nan\n",
    "gdf['avg_street_length'] = np.nan\n",
    "gdf['intersection_density'] = np.nan\n",
    "gdf['street_density'] = np.nan\n",
    "gdf['avg_circuity'] = np.nan\n",
    "gdf['avg_node_connectivity'] = np.nan\n",
    "gdf['avg_PageRank'] = np.nan\n",
    "gdf['avg_betweenness_centrality'] = np.nan\n",
    "gdf['avg_local_closeness_centrality'] = np.nan\n",
    "gdf['avg_global_closeness_centrality'] = np.nan\n",
    "gdf['avg_straightness_centrality'] = np.nan\n",
    "\n",
    "# Built Complexity/Morphology\n",
    "gdf['avg_building_area'] = np.nan\n",
    "gdf['avg_tesselation_area'] = np.nan\n",
    "gdf['avg_building_height'] = np.nan\n",
    "gdf['avg_building_volume'] = np.nan\n",
    "gdf['avg_building_orientation'] = np.nan\n",
    "gdf['avg_tessellation_orientation'] = np.nan\n",
    "gdf['avg_building_cell_alignment'] = np.nan\n",
    "gdf['avg_street_alignment'] = np.nan\n",
    "gdf['avg_width-street_profile'] = np.nan\n",
    "gdf['avg_width_deviations-street_profile'] = np.nan\n",
    "gdf['avg_openness-street_profile'] = np.nan\n",
    "gdf['avg_heights-street_profile'] = np.nan\n",
    "gdf['avg_heights_deviations-street_profile'] = np.nan\n",
    "gdf['avg_profile-street_profile'] = np.nan\n",
    "gdf['avg_building_compactness'] = np.nan\n",
    "\n",
    "# Infrastructure variables/KPIs\n",
    "gdf['total_area'] = np.nan\n",
    "gdf['total_built_area'] = np.nan\n",
    "gdf['total_street_length'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37344c62-af87-4bb1-8655-187a31ceb9f1",
   "metadata": {},
   "source": [
    "# Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "933489ac-4e64-423b-bbc1-fde7a85d178e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1 out of 1: ID = 0\n"
     ]
    }
   ],
   "source": [
    "last_ID = 0\n",
    "bookmark = True\n",
    "\n",
    "# iterate through boundaries    \n",
    "for ID in gdf.index: \n",
    "    \n",
    "    # Pick up where we left off or the loop broke\n",
    "    if (ID != last_ID) and (bookmark == True):\n",
    "        continue\n",
    "    else:\n",
    "        bookmark = False\n",
    "    \n",
    "    print(f\"Run {ID+1} out of {len(gdf)}: ID = {ID}\")\n",
    "    \n",
    "    try:\n",
    "        # get primary geometry and load network\n",
    "        polygon = gdf.loc[ID,'geometry']\n",
    "        G = ox.graph_from_polygon(polygon, network_type='drive', simplify=True, retain_all=False, truncate_by_edge=True, clean_periphery=True, custom_filter=None)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    ####################\n",
    "    # Scale Complexity #\n",
    "    ####################\n",
    "    \n",
    "    try:\n",
    "        fp = f'./street-network-{ID}.png'\n",
    "        ox.plot_graph(G,bgcolor='white',node_color='black',edge_color='black',show=False,close=True,dpi=150,save=True,filepath=fp)\n",
    "        I = imageio.imread(fp, as_gray=\"True\")/255.0\n",
    "        ! rm $fp # comment if you want to save the plot\n",
    "        gdf.loc[ID,'fractal-dimension'] = fractal_dimension(I)\n",
    "    except:\n",
    "        pass\n",
    "  \n",
    "    try:\n",
    "        gdf.loc[ID,'compactness-area'] = pp_compactness(polygon)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        gdf.loc[ID,'diameter-periphery'] = nx.diameter(G.to_undirected())\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #######################################\n",
    "    # Spatial Complexity and Connectivity #\n",
    "    #######################################\n",
    "    \n",
    "    try:\n",
    "        # get 'shannon_entropy-street_orientation_order'\n",
    "        bearings = get_bearings(G, ID)\n",
    "        count = count_and_merge(36, bearings)\n",
    "        street_orientation_order = get_orientation_order(count)\n",
    "        gdf.loc[ID,'shannon_entropy-street_orientation_order'] = street_orientation_order\n",
    "        #print(street_orientation_order)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        # get basic stats from network\n",
    "        basic = ox.stats.basic_stats(G, area=gdf.loc[ID,\"area_m^2\"]) # basic stats\n",
    "    \n",
    "        # allocate stats\n",
    "        gdf.loc[ID,'avg_streets_per_node'] = basic['streets_per_node_avg']\n",
    "        gdf.loc[ID,'avg_proportion_streets_per_node'] = np.mean(list(basic['streets_per_node_proportions'].values()))\n",
    "        gdf.loc[ID,'avg_street_length'] = basic['street_length_avg']\n",
    "        gdf.loc[ID,'intersection_density'] = basic['node_density_km']\n",
    "        gdf.loc[ID,'street_density'] = basic['street_density_km']\n",
    "        gdf.loc[ID,'avg_circuity'] = basic['circuity_avg']\n",
    "        gdf.loc[ID,'avg_node_connectivity'] = np.mean(nx.node_connectivity(G))\n",
    "        gdf.loc[ID,'avg_PageRank'] = np.mean(list(nx.pagerank(G).values()))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        # multiple centrality assessment\n",
    "        streets_graph = ox.projection.project_graph(G)\n",
    "        edges = ox.graph_to_gdfs(ox.get_undirected(streets_graph), nodes=False, edges=True,node_geometry=False, fill_edge_geometry=True)\n",
    "        primal = momepy.gdf_to_nx(edges, approach='primal')\n",
    "        primal = momepy.closeness_centrality(primal, radius=gdf.loc[ID,'diameter-periphery']*(1/4), name='closeness_local', distance='mm_len', weight='mm_len')\n",
    "        primal = momepy.closeness_centrality(primal, name='closeness_global', weight='mm_len')\n",
    "        primal = momepy.betweenness_centrality(primal, name='betweenness_metric_n', mode='nodes', weight='mm_len')\n",
    "        primal = momepy.straightness_centrality(primal)\n",
    "        nodes = momepy.nx_to_gdf(primal, lines=False)\n",
    "\n",
    "        gdf.loc[ID,'avg_betweenness_centrality'] = np.mean(nodes['betweenness_metric_n'])\n",
    "        gdf.loc[ID,'avg_local_closeness_centrality'] = np.mean(nodes['closeness_local'])\n",
    "        gdf.loc[ID,'avg_global_closeness_centrality'] = np.mean(nodes['closeness_global'])\n",
    "        gdf.loc[ID,'avg_straightness_centrality'] = np.mean(nodes['straightness'])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    ###############################\n",
    "    # Built Complexity/Morphology #\n",
    "    ###############################\n",
    "    \n",
    "    try:\n",
    "        buildings_gdf = ox.geometries_from_polygon(polygon, tags={'building':True})\n",
    "        buildings_gdf_projected = ox.project_gdf(buildings_gdf)\n",
    "        buildings_gdf_projected = buildings_gdf_projected.reset_index()\n",
    "        buildings_gdf_projected = buildings_gdf_projected[buildings_gdf_projected.geom_type.isin(['Polygon', 'MultiPolygon'])]\n",
    "\n",
    "        buildings = momepy.preprocess(buildings_gdf_projected, size=30, compactness=True, islands=True)\n",
    "        buildings['uID'] = momepy.unique_id(buildings)\n",
    "\n",
    "        limit = momepy.buffered_limit(buildings)\n",
    "\n",
    "        tess = momepy.Tessellation(buildings, unique_id='uID', limit=limit)\n",
    "        tessellation = tess.tessellation\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        blg_area = momepy.Area(buildings)\n",
    "        buildings['area'] = blg_area.series\n",
    "        gdf.loc[ID,'avg_building_area'] = buildings['area'].mean()\n",
    "\n",
    "        tes_area = momepy.Area(tessellation)\n",
    "        tessellation['area'] = tes_area.series\n",
    "        gdf.loc[ID,'avg_tesselation_area'] = tessellation['area'].mean()\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        # try to fix heights\n",
    "        buildings['height'] = buildings['height'].fillna(0).apply(clean_heights)\n",
    "        if buildings['height'].mean() == 0:\n",
    "            pass\n",
    "        else:\n",
    "            gdf.loc[ID,'avg_building_height'] = buildings['height'].mean()\n",
    "\n",
    "        blg_volume = momepy.Volume(buildings, heights='height')\n",
    "        buildings['volume'] = blg_volume.series\n",
    "        if buildings['volume'].mean() == 0:\n",
    "            pass\n",
    "        else:\n",
    "            gdf.loc[ID,'avg_building_volume'] = buildings['volume'].mean()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    try:    \n",
    "        buildings['orientation'] = momepy.Orientation(buildings).series\n",
    "        gdf.loc[ID,'avg_building_orientation'] = buildings['orientation'].mean()\n",
    "\n",
    "        tessellation['orientation'] = momepy.Orientation(tessellation).series\n",
    "        gdf.loc[ID,'avg_tessellation_orientation'] = tessellation['orientation'].mean() \n",
    "\n",
    "        blg_cell_align = momepy.CellAlignment(buildings, tessellation,'orientation', 'orientation','uID', 'uID')\n",
    "        buildings['cell_align'] = blg_cell_align.series\n",
    "        gdf.loc[ID,'avg_building_cell_alignment'] = buildings['cell_align'].mean()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        edges['networkID'] = momepy.unique_id(edges)\n",
    "        buildings['networkID'] = momepy.get_network_id(buildings, edges, 'networkID')\n",
    "        buildings_net = buildings.loc[buildings.networkID >= 0]\n",
    "        str_align = momepy.StreetAlignment(buildings_net, edges,'orientation', 'networkID','networkID')\n",
    "        buildings_net['str_align'] = str_align.series\n",
    "        gdf.loc[ID,'avg_street_alignment'] = buildings_net['str_align'].mean()\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        profile = momepy.StreetProfile(edges, buildings, heights='height')\n",
    "        edges['widths'] = profile.w\n",
    "        edges['width_deviations'] = profile.wd\n",
    "        edges['openness'] = profile.o\n",
    "        edges['heights'] = profile.h\n",
    "        edges['heights_deviations'] = profile.hd\n",
    "        edges['profile'] = profile.p\n",
    "    \n",
    "        gdf.loc[ID,'avg_width-street_profile'] = edges['widths'].mean()\n",
    "        gdf.loc[ID,'avg_width_deviations-street_profile'] = edges['widths'].mean()\n",
    "        gdf.loc[ID,'avg_openness-street_profile'] = edges['widths'].mean()\n",
    "        gdf.loc[ID,'avg_heights-street_profile'] = edges['widths'].mean()\n",
    "        gdf.loc[ID,'avg_heights_deviations-street_profile'] = edges['widths'].mean()\n",
    "        gdf.loc[ID,'avg_profile-street_profile'] = edges['widths'].mean()\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        buildings['compactness'] = buildings['geometry'].apply(lambda x: pp_compactness(x))\n",
    "        gdf.loc[ID,'avg_building_compactness'] = buildings['compactness'].mean()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #################################\n",
    "    # Infrastructure variables/KPIs #\n",
    "    ################################# \n",
    "    \n",
    "    try:\n",
    "        gdf.loc[ID,'total_area'] = gdf.loc[ID,\"area_m^2\"]\n",
    "        gdf.loc[ID,'total_built_area'] = buildings['area'].sum()\n",
    "        gdf.loc[ID,'total_street_length'] = basic['street_length_total']\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "gdf['UID'] = gdf.index "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5173f080-1718-4203-bf0d-8bbc1a4b4b5b",
   "metadata": {},
   "source": [
    "# Report data availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "156af1c3-4bb2-43e6-a14f-3c16057cad73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_betweenness_centrality               -> missing\n",
      "fractal-dimension                        -> missing\n",
      "shannon_entropy-street_orientation_order -> available\n",
      "avg_street_length                        -> available\n",
      "avg_building_area                        -> missing\n",
      "avg_building_compactness                 -> missing\n"
     ]
    }
   ],
   "source": [
    "vars_of_interest = [\n",
    "    'avg_betweenness_centrality',\n",
    "    'fractal-dimension',\n",
    "    'shannon_entropy-street_orientation_order',\n",
    "    'avg_street_length',\n",
    "    'avg_building_area',\n",
    "    'avg_building_compactness']\n",
    "\n",
    "for variable in vars_of_interest:\n",
    "    if gdf[variable].isna().all():\n",
    "        print(f\"{variable:<40} -> missing\")\n",
    "    else:\n",
    "        print(f\"{variable:<40} -> available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c03d24-8ac2-4934-99ca-df1cea91856d",
   "metadata": {},
   "source": [
    "# Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62d268fe-b2d3-49c9-b104-617090a3e17b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving: ../data/morphometrics/Los Angeles - morpho.gpkg\n"
     ]
    }
   ],
   "source": [
    "out_file = data_folder / \"2_morphometrics\" / (city + \" - morpho.gpkg\")\n",
    "print(\"Saving:\", out_file)\n",
    "gdf.to_file(out_file, driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfe44bd-b8ac-4d5d-9c38-7bc41e0e68f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
